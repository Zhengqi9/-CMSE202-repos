{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align: right;\"> &#9989; Qingxuan Zheng\n",
    "#### <p style=\"text-align: right;\"> &#9989; Put your group member names here</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for the day\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "import time\n",
    "from sklearn.datasets import make_circles\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Review of Pre-Class assignment\n",
    "\n",
    "We'll discussion any questions that came up as a class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Non-linear svm\n",
    "\n",
    "If you played with the data a bit or looked around on the web, you should have been able to find a third dimension that would have made separability of the circle data possible.\n",
    "\n",
    "Let's set the new Z coordinate to:\n",
    "\n",
    "$$ Z = X^{2} + Y^{2} $$\n",
    "\n",
    "for all the data in $X$ and $Y$. If you do this with `numpy`, it is a single line of code (no loop required).\n",
    "\n",
    "<font size=8 color=\"#009600\">&#9998;</font> Do this - Make a 2D circle data set, add the specified Z coordinate and plot it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2a2aace34d04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_circles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m df['z'] = (\n\u001b[0;32m----> 4\u001b[0;31m     (df['x']) ** 2 +  (df['y']) ** 2  ) \n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# your answer here\n",
    "X, y = make_circles(n_samples=100, random_state=123, noise=0.05)\n",
    "df['z'] = (\n",
    "    (df['x']) ** 2 +  (df['y']) ** 2  ) \n",
    "\n",
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 SVM on modified data set\n",
    "\n",
    "Note that we have not added any data to our circle data, we simply created a new dimension **based** on the existing data. In so doing it seems fairly obvious that we can now separate that data. \n",
    "\n",
    "**Question:** If we were to run an SVM on the modified data, is the data linearly separable? What dimensionality would the separating element be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=8 color=\"#009600\">&#9998;</font> If linearly separable, what dimension element is required? I think we need to make a subplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 3. How to find that \"special\" dimension\n",
    "\n",
    "It seems like we just pulled that special Z dimension out of thin air. How is it possible to find such a dimension that might make non-linear data linearly separable? That is what SVM can do. \n",
    "\n",
    "The math needed to do this is beyond the scope of this course. But, here is the basic idea:\n",
    "- we need to define a function $\\phi$ that transforms the existing data into a new feature space (a function based on the existing values to generate the new dimension) that would allow us to do better separation.\n",
    "   - we train and test in that new space, the result of applying $\\phi$ into the feature space\n",
    "- there is a process called <a href=\"https://en.wikipedia.org/wiki/Kernel_method\"> the kernel trick </a> \n",
    "    - The kernel trick avoids the explicit mapping that is needed to get linear learning algorithms to learn a nonlinear function or decision boundary. You learned a little about that in the pre-class.\n",
    "    \n",
    "Wikipedia describes it well:\n",
    "\n",
    "> Kernel methods can be thought of as instance-based learners: rather than learning some fixed set of parameters corresponding to the features of their inputs, they instead \"remember\" the  i-th training example $( x_i , y_i ) $ and learn for it a corresponding weight $w_i$. Prediction for unlabeled inputs, i.e., those not in the training set, is treated by the application of a similarity function **k**, called a kernel, between the unlabeled input $x â€²$ and each of the training inputs $x_i$\n",
    "\n",
    "As you saw in the pre-class, one such useful \"kernel\" is called the \"radial basis function\", \n",
    "$$ k(x^{i}, x^{j}) = exp( -\\frac {\\| x^{i} -x^{j}\\|^{2}} {2\\sigma^{2}}) $$\n",
    "where\n",
    "$$ \\gamma = \\frac{1}{2\\sigma} $$ \n",
    "making\n",
    "$$ k(x^{i}, x^{j}) = exp(-\\gamma \\|x^{i} - x^{j} \\| ^{2}) $$\n",
    "and $\\gamma$ is a parameter to be optimized (like `C` in the linear case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 4. Example using the digits dataset\n",
    "\n",
    "Let's start with downloading a dataset called \"digits\" which is included in the sklearn library. That's right, `sklearn` comes with datasets all ready for us to use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import fetch_lfw_people, load_digits\n",
    "\n",
    "sk_data = load_digits();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cool slider to browse all of the images.\n",
    "from ipywidgets import interact\n",
    "def browse_images(images, labels, categories):\n",
    "    n = len(images)\n",
    "    def view_image(i):\n",
    "        plt.imshow(images[i], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        plt.title('%s' % categories[labels[i]])\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    interact(view_image, i=(0,n-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browse_images(sk_data.images, sk_data.target, sk_data.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Getting the data\n",
    "\n",
    "The `sklearn` data comes in a particular format we need to work with. Please take a look at <a href=\"https://scikit-learn.org/stable/datasets/index.html\"> https://scikit-learn.org/stable/datasets/index.html </a> for a quick overview. Now let's inspect the digits arrays to find out what the shapes of the arrays (which can help for plotting the data with matplotlib). **Review the code below and make sure you know what it is doing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sk_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-15c04854454f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msk_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclass_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msk_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msk_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sk_data' is not defined"
     ]
    }
   ],
   "source": [
    "feature_vectors = sk_data.data\n",
    "class_labels = sk_data.target\n",
    "categories = sk_data.target_names\n",
    "\n",
    "n_samples, n_features = feature_vectors.shape\n",
    "N, h, w = sk_data.images.shape\n",
    "n_classes = len(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Write some code to print out the number of samples, number of features, number of classes, and the shape of the image dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0a2454d3c909>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Put your answer to the above question here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_samples' is not defined"
     ]
    }
   ],
   "source": [
    "#Put your answer to the above question here\n",
    "print(n_samples)\n",
    "print(n_features)\n",
    "print(n_classes)\n",
    "print(N, h, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: As a group discuss the difference between the features, samples, and classes.  How do these relate to the shape of the image?  Write down a quick definition of each (the first one has been done for you):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font size=8 color=\"#009600\">&#9998;</font>\n",
    " \n",
    " \n",
    "1. **n_samples:** Total number of images in the digits dataset. \n",
    "2. **n_features:** Total features the dataset have\n",
    "3. **n_classes:** The number of classes to return\n",
    "4. **N:**\n",
    "5. **h:** The height of the image shape\n",
    "6. **w:** The width of the image shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Distribution of classes in our data\n",
    "\n",
    "Let's have a look at the distribution of samples across the target classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-79584b068d6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_unique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_labels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_unique\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'class_labels' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x216 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 3))\n",
    "\n",
    "y_unique = np.unique(class_labels)\n",
    "counts = [(class_labels == i).sum() for i in y_unique]\n",
    "\n",
    "plt.xticks(y_unique,  categories[y_unique])\n",
    "locs, labels = plt.xticks()\n",
    "plt.setp(labels, rotation=45, size=20)\n",
    "_ = plt.bar(y_unique, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Does this seem like a good set of samples for training our machine learning algorithm? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font size=8 color=\"#009600\">&#9998;</font> Do This - I think it is not a good set of samples for training our machine learning algorithm because the size a each numner looks a sightly different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Train a SVM Classifier based on the training dataset.\n",
    "\n",
    "Let's split the data into a training set and final testing set as we have done in the past.\n",
    "\n",
    "We've used `train_test_split` before so do it here now. To stay in sync with the code below, create:\n",
    "- `train_vectors` and `train_labels` for the training feature vectors and corresponding class labels\n",
    "- `test_vectors` and `test_labels` for the test feature vectors and labels. \n",
    "\n",
    "Do that below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_unique' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b8c22f9a34f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# your answer here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_unique\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_unique' is not defined"
     ]
    }
   ],
   "source": [
    "# your answer here\n",
    "train_test_split(y_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Optimizing hyper-parameters\n",
    "\n",
    "There are two parameters we might try to optimize to get better results:\n",
    "- the C parameter of SVM. We discussed this in the previous in-class\n",
    "- the $\\gamma$ parameter of rbf (our radial basis function kernel)\n",
    "\n",
    "These tuning parameters are often called **hyper-parameters**. These are parameters that affect the algorithm's \"learning\" process.\n",
    "\n",
    "### 4.4.1 The C parameter\n",
    "\n",
    "Here's another way to describe `c`. There are two types of SVM classifiers: hard margin and soft margin. Most SVM implementations are soft margin because \"soft\" allows for some points to be mis-classified when defining the margin (hard margin does not). The **C** parameter of the `svm.SVC` helps in choosing how \"soft\" to be:\n",
    "- small values of C allow for some point misclassification but lower the effect of noisy outliers\n",
    "- larger values of C push to accomodate even noisy points in favor of higher efficiency\n",
    "\n",
    "### 4.4.2 The $\\gamma$ parameter\n",
    "The $\\gamma$ value is part of the rbf (radial basis function). Intuitively, a small gamma value defines a Gaussian function with a large variance. In this case, two points can be considered similar even if are far from each other. On the other hand, a large gamma value  defines a Gaussian function with a small variance and in this case, two points are considered similar just if they are close to each other. \n",
    "\n",
    "### 4.4.3 `GridSearchCV` and choosing hyper-parameters\n",
    "It can be difficult to search for an optimal combination of a set of hyper-parameters. What is the best combination of $C$ and $\\gamma$ for our digits data set? One way to avoid the issue is to test combinations of a fixed set of each hyper-parameter and evaluate which combinations are optimal. In this was we trade time (time to do all the testing) for better results.\n",
    "\n",
    "Below we import <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\"> `GridSearchCV` </a> from `sklearn.model.selection`. The idea behind it is pretty simple:\n",
    "- provide a list of hyper-parameters and, for each hyper-parameter, a set of values you which to test.\n",
    "- `GridSearchCV` will **exhaustively** search, that is will try **all combinations** of the listed parameters, and based on the **best combination** will return results.\n",
    "\n",
    "The above terms **exhautively** and **all combinations** are a kind of warning. These mean that considerable computational effort might be required to evaluate which hyper-parameter combinations is \"best\".\n",
    "\n",
    "#### How Long\n",
    "The code below takes about 20 seconds on my rather newish Lenovo laptop. Be patient, might take longer depending on what you are using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Training the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0145e4a29521>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#make some temporary variables so you can change this easily\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtmp_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtmp_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Train a SVM classification model\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "#make some temporary variables so you can change this easily\n",
    "tmp_vectors = train_vectors\n",
    "tmp_labels = train_labels\n",
    "\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "# a dictionary of hyperparameters: key is the name of the parameter, value is a list of values to test\n",
    "param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "# make a classifier by searching over a classifier and the parameter grid\n",
    "clf = GridSearchCV(SVC(kernel='linear', class_weight='balanced'), param_grid)\n",
    "\n",
    "# we have a \"good\" classifier (according to GridSearchCV), how's it look\n",
    "clf = clf.fit(tmp_vectors, tmp_labels)\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Runtime\",end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **DO THIS**: Explore the ```clf``` object. What functions does it have access to?  Can you figure out what function you may use to input a unknown feature vector and make a class prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO THIS, put your exploration code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Show the results of the classification on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4bb627fa1201>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#make some temporary variables so you can change this easily\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredict_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Quantitative evaluation of the model quality on the test set\n",
    "\n",
    "#make some temporary variables so you can change this easily\n",
    "predict_vectors = test_vectors\n",
    "true_labels = test_labels\n",
    "\n",
    "print(\"Predicting names on the test set\")\n",
    "pred_labels = clf.predict(predict_vectors)\n",
    "\n",
    "print(classification_report(true_labels, pred_labels))\n",
    "print(confusion_matrix(true_labels, pred_labels, labels=range(n_classes)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4fe801beeafc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplot_gallery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_gallery(images, true_titles, pred_titles, h, w, n_row=5, n_col=5):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray_r)\n",
    "        plt.title('Pred='+str(categories[pred_titles[i]]), size=9)\n",
    "        plt.xlabel('Actual='+str(categories[true_titles[i]]), size=9)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "plot_gallery(test_vectors, test_labels, pred_labels, h,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How well is the classifier doing with the digits dataset? Comment on what information the classification report and confusion matrix provide you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=8 color=\"#009600\">&#9998;</font> The classifier doing great with the digits dataset. The classification report and confusion matrix provide me how the precision and actual number will match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:** What if you created a new random training set from the images using the same fraction of images? What if you just used all of the data -- does it work better or worse? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=8 color=\"#009600\">&#9998;</font> If you created a new random training set from the images using the same fraction of images, I think it will come up a different confusion matrix. If I just used all of the data, I think it will work worse because it may make more error on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Face Recognition\n",
    "\n",
    "Now that we have completed the example for digits dataset. Lets do it again with some faces. Fortunately, scikit-learn comes with a face dataset in exactly the same format as the digits dataset.  This means we should just be able to swap out one with the other. Here is the code for importing the faces data.  This code ensures there are at least 50 faces per person and they are resized to 40%.  \n",
    "\n",
    "Make sure you go back to the top and our imports section and uncomment the `fetch_lfw_people` part.\n",
    "\n",
    "```sk_data = fetch_lfw_people(min_faces_per_person=50, resize=0.4)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **DO THIS**:  Repeat the entire process using the face database imported with the command shown above. Answer the following questions.\n",
    "\n",
    "**Note: you should not need to update any of the provided code as it all hinges on `sk_data`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 83.      ,  91.666664, 112.      , ..., 112.333336, 146.      ,\n",
       "         124.333336],\n",
       "        [ 38.666668,  69.666664,  84.666664, ...,  67.      ,  88.333336,\n",
       "         115.      ],\n",
       "        [ 82.666664,  58.      ,  59.      , ..., 171.33333 ,  90.333336,\n",
       "          82.333336],\n",
       "        ...,\n",
       "        [ 50.333332,  65.666664,  88.      , ..., 197.      , 179.33333 ,\n",
       "         166.33333 ],\n",
       "        [138.      , 158.66667 , 169.66667 , ..., 232.66667 , 228.33333 ,\n",
       "         226.      ],\n",
       "        [ 30.      ,  27.      ,  32.666668, ...,  35.      ,  35.333332,\n",
       "          61.      ]], dtype=float32),\n",
       " 'images': array([[[ 83.      ,  91.666664, 112.      , ...,  54.333332,\n",
       "           62.      ,  76.333336],\n",
       "         [ 89.      ,  95.      , 100.      , ...,  51.666668,\n",
       "           47.666668,  69.333336],\n",
       "         [ 93.      ,  93.666664,  85.333336, ...,  62.      ,\n",
       "           47.666668,  56.      ],\n",
       "         ...,\n",
       "         [ 48.666668,  46.666668,  45.666668, ..., 177.66667 ,\n",
       "          131.33333 ,  89.333336],\n",
       "         [ 48.      ,  47.      ,  46.      , ..., 149.66667 ,\n",
       "          141.      , 101.333336],\n",
       "         [ 47.666668,  47.      ,  45.666668, ..., 112.333336,\n",
       "          146.      , 124.333336]],\n",
       " \n",
       "        [[ 38.666668,  69.666664,  84.666664, ...,  66.333336,\n",
       "           46.      ,  43.      ],\n",
       "         [ 47.333332,  78.333336,  84.666664, ...,  80.666664,\n",
       "           57.      ,  52.333332],\n",
       "         [ 55.333332,  82.333336,  84.666664, ...,  94.      ,\n",
       "           63.      ,  56.      ],\n",
       "         ...,\n",
       "         [ 12.      ,  60.666668, 133.      , ..., 214.66667 ,\n",
       "          202.      , 194.      ],\n",
       "         [ 11.666667,  63.      , 134.33333 , ..., 120.666664,\n",
       "          124.333336, 127.      ],\n",
       "         [ 11.      ,  65.666664, 135.33333 , ...,  67.      ,\n",
       "           88.333336, 115.      ]],\n",
       " \n",
       "        [[ 82.666664,  58.      ,  59.      , ..., 101.666664,\n",
       "           97.333336,  97.333336],\n",
       "         [ 69.      ,  64.      ,  59.666668, ...,  97.666664,\n",
       "           96.333336,  97.666664],\n",
       "         [ 61.666668,  57.666668,  60.      , ...,  98.      ,\n",
       "           95.333336,  96.      ],\n",
       "         ...,\n",
       "         [111.666664, 108.      , 110.      , ..., 166.      ,\n",
       "          142.33333 , 127.333336],\n",
       "         [112.      , 112.      , 114.      , ..., 172.      ,\n",
       "          136.33333 , 123.666664],\n",
       "         [114.      , 114.333336, 115.333336, ..., 171.33333 ,\n",
       "           90.333336,  82.333336]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 50.333332,  65.666664,  88.      , ..., 159.      ,\n",
       "          158.66667 , 152.      ],\n",
       "         [ 59.666668,  83.      ,  99.333336, ..., 157.66667 ,\n",
       "          150.66667 , 149.66667 ],\n",
       "         [ 62.      ,  90.666664,  94.333336, ..., 157.33333 ,\n",
       "          145.      , 144.      ],\n",
       "         ...,\n",
       "         [ 59.666668,  60.666668,  62.      , ..., 151.66667 ,\n",
       "          166.66667 , 164.66667 ],\n",
       "         [ 60.333332,  61.333332,  63.      , ..., 187.33333 ,\n",
       "          176.33333 , 167.      ],\n",
       "         [ 61.333332,  61.333332,  62.333332, ..., 197.      ,\n",
       "          179.33333 , 166.33333 ]],\n",
       " \n",
       "        [[138.      , 158.66667 , 169.66667 , ..., 107.666664,\n",
       "           78.333336,  84.333336],\n",
       "         [149.66667 , 160.66667 , 167.66667 , ..., 119.      ,\n",
       "           94.      ,  69.666664],\n",
       "         [154.66667 , 167.      , 170.66667 , ..., 124.333336,\n",
       "           93.666664,  66.333336],\n",
       "         ...,\n",
       "         [ 67.333336,  64.      ,  60.      , ..., 231.33333 ,\n",
       "          229.66667 , 227.      ],\n",
       "         [ 65.666664,  62.666668,  61.333332, ..., 230.      ,\n",
       "          230.66667 , 226.      ],\n",
       "         [ 65.666664,  61.666668,  61.666668, ..., 232.66667 ,\n",
       "          228.33333 , 226.      ]],\n",
       " \n",
       "        [[ 30.      ,  27.      ,  32.666668, ...,  89.666664,\n",
       "           53.333332,  46.666668],\n",
       "         [ 31.333334,  32.      ,  37.333332, ..., 104.      ,\n",
       "           56.333332,  42.666668],\n",
       "         [ 33.666668,  33.666668,  39.      , ..., 122.666664,\n",
       "           71.333336,  52.      ],\n",
       "         ...,\n",
       "         [ 45.666668,  44.      ,  43.333332, ...,  23.333334,\n",
       "           20.      ,  34.333332],\n",
       "         [ 42.333332,  42.      ,  44.333332, ...,  24.333334,\n",
       "           27.      ,  44.      ],\n",
       "         [ 45.666668,  49.333332,  51.333332, ...,  35.      ,\n",
       "           35.333332,  61.      ]]], dtype=float32),\n",
       " 'target': array([11,  4,  2, ...,  3, 11,  5]),\n",
       " 'target_names': array(['Ariel Sharon', 'Colin Powell', 'Donald Rumsfeld', 'George W Bush',\n",
       "        'Gerhard Schroeder', 'Hugo Chavez', 'Jacques Chirac',\n",
       "        'Jean Chretien', 'John Ashcroft', 'Junichiro Koizumi',\n",
       "        'Serena Williams', 'Tony Blair'], dtype='<U17'),\n",
       " 'DESCR': \".. _labeled_faces_in_the_wild_dataset:\\n\\nThe Labeled Faces in the Wild face recognition dataset\\n------------------------------------------------------\\n\\nThis dataset is a collection of JPEG pictures of famous people collected\\nover the internet, all details are available on the official website:\\n\\n    http://vis-www.cs.umass.edu/lfw/\\n\\nEach picture is centered on a single face. The typical task is called\\nFace Verification: given a pair of two pictures, a binary classifier\\nmust predict whether the two images are from the same person.\\n\\nAn alternative task, Face Recognition or Face Identification is:\\ngiven the picture of the face of an unknown person, identify the name\\nof the person by referring to a gallery of previously seen pictures of\\nidentified persons.\\n\\nBoth Face Verification and Face Recognition are tasks that are typically\\nperformed on the output of a model trained to perform Face Detection. The\\nmost popular model for Face Detection is called Viola-Jones and is\\nimplemented in the OpenCV library. The LFW faces were extracted by this\\nface detector from various online websites.\\n\\n**Data Set Characteristics:**\\n\\n    =================   =======================\\n    Classes                                5749\\n    Samples total                         13233\\n    Dimensionality                         5828\\n    Features            real, between 0 and 255\\n    =================   =======================\\n\\nUsage\\n~~~~~\\n\\n``scikit-learn`` provides two loaders that will automatically download,\\ncache, parse the metadata files, decode the jpeg and convert the\\ninteresting slices into memmapped numpy arrays. This dataset size is more\\nthan 200 MB. The first load typically takes more than a couple of minutes\\nto fully decode the relevant part of the JPEG files into numpy arrays. If\\nthe dataset has  been loaded once, the following times the loading times\\nless than 200ms by using a memmapped version memoized on the disk in the\\n``~/scikit_learn_data/lfw_home/`` folder using ``joblib``.\\n\\nThe first loader is used for the Face Identification task: a multi-class\\nclassification task (hence supervised learning)::\\n\\n  >>> from sklearn.datasets import fetch_lfw_people\\n  >>> lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\\n\\n  >>> for name in lfw_people.target_names:\\n  ...     print(name)\\n  ...\\n  Ariel Sharon\\n  Colin Powell\\n  Donald Rumsfeld\\n  George W Bush\\n  Gerhard Schroeder\\n  Hugo Chavez\\n  Tony Blair\\n\\nThe default slice is a rectangular shape around the face, removing\\nmost of the background::\\n\\n  >>> lfw_people.data.dtype\\n  dtype('float32')\\n\\n  >>> lfw_people.data.shape\\n  (1288, 1850)\\n\\n  >>> lfw_people.images.shape\\n  (1288, 50, 37)\\n\\nEach of the ``1140`` faces is assigned to a single person id in the ``target``\\narray::\\n\\n  >>> lfw_people.target.shape\\n  (1288,)\\n\\n  >>> list(lfw_people.target[:10])\\n  [5, 6, 3, 1, 0, 1, 3, 4, 3, 0]\\n\\nThe second loader is typically used for the face verification task: each sample\\nis a pair of two picture belonging or not to the same person::\\n\\n  >>> from sklearn.datasets import fetch_lfw_pairs\\n  >>> lfw_pairs_train = fetch_lfw_pairs(subset='train')\\n\\n  >>> list(lfw_pairs_train.target_names)\\n  ['Different persons', 'Same person']\\n\\n  >>> lfw_pairs_train.pairs.shape\\n  (2200, 2, 62, 47)\\n\\n  >>> lfw_pairs_train.data.shape\\n  (2200, 5828)\\n\\n  >>> lfw_pairs_train.target.shape\\n  (2200,)\\n\\nBoth for the :func:`sklearn.datasets.fetch_lfw_people` and\\n:func:`sklearn.datasets.fetch_lfw_pairs` function it is\\npossible to get an additional dimension with the RGB color channels by\\npassing ``color=True``, in that case the shape will be\\n``(2200, 2, 62, 47, 3)``.\\n\\nThe :func:`sklearn.datasets.fetch_lfw_pairs` datasets is subdivided into\\n3 subsets: the development ``train`` set, the development ``test`` set and\\nan evaluation ``10_folds`` set meant to compute performance metrics using a\\n10-folds cross validation scheme.\\n\\n.. topic:: References:\\n\\n * `Labeled Faces in the Wild: A Database for Studying Face Recognition\\n   in Unconstrained Environments.\\n   <http://vis-www.cs.umass.edu/lfw/lfw.pdf>`_\\n   Gary B. Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller.\\n   University of Massachusetts, Amherst, Technical Report 07-49, October, 2007.\\n\\n\\nExamples\\n~~~~~~~~\\n\\n:ref:`sphx_glr_auto_examples_applications_plot_face_recognition.py`\\n\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy the code above with the modified data set and paste it here\n",
    "\n",
    "sk_data = fetch_lfw_people(min_faces_per_person=50, resize=0.4)\n",
    "sk_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How long did it take to train the face recognition classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=8 color=\"#009600\">&#9998;</font> From the result that I run out, I couln't find out hoe long it take to train the face recognition classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How well did the SVM algorithm work on the face recognition problem?  Can you think of real world applications where this level of face recognition may be acceptable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=8 color=\"#009600\">&#9998;</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Why is the face recognition not working as well?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=8 color=\"#009600\">&#9998;</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Give some example science problems where this type of machine learning classification (SVM) may be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=8 color=\"#009600\">&#9998;</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Congratulations, we're done!\n",
    "\n",
    "Now, you just need to submit this assignment by uploading it to the course <a href=\"https://d2l.msu.edu/\">Desire2Learn</a> web page for today's submission folder (Don't forget to add your names in the first cell).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#169; Copyright Michigan State University Board of Trustees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
